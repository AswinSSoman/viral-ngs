"""
    This is a basic framework for assembly of viral genomes, currently
    tailored for EBOV. Some generalization work needed to expand this
    to generic viral genomes with an arbitrary number of segments/chromosomes.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time, shutil


rule all_assemble:
    input:
        # create final assemblies for all samples
        expand("{data_dir}/{subdir}/{sample}.fasta",
            data_dir=config["data_dir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
        # create BAMs of aligned reads to own consensus
        expand("{data_dir}/{subdir}/{sample}.bam",
            data_dir=config["data_dir"], subdir=config["subdirs"]["align_self"],
            sample=read_samples_file(config["samples_assembly"]))
    params: LSF="-N"

rule all_assemble_failures:
    input:
        expand("{data_dir}/{subdir}/{sample}.fasta",
            data_dir=config["data_dir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config.get("samples_assembly_failures")))
    params: LSF="-N"



rule assemble_trinity:
    ''' This step runs the Trinity assembler.
        First trim reads with trimmomatic, rmdup with prinseq,
        and random subsample to no more than 100k reads.
    '''
    input:  config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.taxfilt.bam'
    output: config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity.fasta'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            n_reads=str(config["trinity_n_reads"]),
            logid="{sample}",
            clipDb=config["trim_clip_db"],
            subsamp_bam=config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.subsamp.bam',
            numThreads=str(config.get("number_of_threads", 1))
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["data_dir"],config["tmp_dir"]],
                subdir=config["subdirs"]["assembly"]))
            shell("{config[bin_dir]}/assembly.py assemble_trinity {input} {params.clipDb} {output} --n_reads={params.n_reads} --outReads {params.subsamp_bam} --threads {params.numThreads} --JVMmemory 5g")

rule assemble_spades:
    ''' This step runs the SPAdes assembler.
    '''
    input:  config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.subsamp.bam'
    output: config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-spades.fasta'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="{sample}",
            numThreads=str(config.get("number_of_threads", 1)),
            spades_use=bool(config.get("spades_use", False))
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["data_dir"],config["tmp_dir"]],
                subdir=config["subdirs"]["assembly"]))
            if params.spades_use:
                shell("{config[bin_dir]}/assembly.py assemble_spades {input} {output}")
            else:
                shell("touch {output}")


rule combine_de_novo_contigs:
    '''Combine de novo contigs obtained by different assemblers'''
    input: config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity.fasta',
           config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-spades.fasta'
    output: config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity-spades.fasta'
    run:
            shell("cat {input[0]} {input[1]} > {output[0]}")

rule choose_scaffolding_reference:
    '''Identify the reference that best matches the sample, so we can scaffold the contigs on it.'''
    input: 
        config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity-spades.fasta',
        config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam',
        config["scafref_dir"] +'/scafref.indexing.done'
    output:
        config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-scafref.fasta'
    run:
        shell("{config[bin_dir]}/scafref.py choose_scafref {config[scafref_dir]} {input[0]} {input[1]}")


rule order_and_orient:
    ''' This step cleans up the Trinity assembly with a known reference genome.
        order_and_orient (MUMmer): take the de novo assembly,
            align them to the known reference genome, switch it to the same
            strand as the reference, and produce chromosome-level assemblies
            (with runs of N's in between the de novo contigs).
        filter_short_seqs: Fail on assemblies that come out to
            < 15kb or < 95% unambiguous.
        impute_from_reference: trim off anything at the end that exceeds
            the length of the known reference assembly.  We also replace all
            Ns and everything within 55bp of the chromosome ends with the
            reference sequence.  This is clearly incorrect consensus sequence,
            but it allows downstream steps to map reads in parts of the genome
            that would otherwise be Ns, and we will correct all of the inferred
            positions with two steps of read-based refinement (below), and
            revert positions back to Ns where read support is lacking.  The
            de novo step is still important because it allows for significant
            structural / indel changes (or significant substitution distances)
            which will be captured in this output.
    '''
    input:  
        config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-trinity.fasta',
        expand( '{refDir}/'+'{ref_name}.fasta', refDir=config["ref_genome_dir"], ref_name="reference" )
    output: 
        config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-scaffolded.fasta'
        #config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-alternate_sequences.fasta'
    resources: mem=12
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            refGenome=os.path.join(config["ref_genome_dir"],"reference"+".fasta"),
            # length should be defined as a fraction/percentage cutoff, relative to 
            # reference length for a given sequence. float is in the config.yaml file
            length = str(config["assembly_min_length_fraction_of_reference"]),
            min_unambig = str(config["assembly_min_unambig"]),
            renamed_prefix="",
            replace_length=str(config.get("assembly_replace_length", 55)),
            logid="{sample}",
            scaffolded_fasta=config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-scaffolded.fasta',
            alternate_fasta=config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-alternate_sequences.fasta'
    run:
            ono_extra = []
            if config.get("assembly_nucmer_max_gap"):
                ono_extra.extend(["--maxgap", str(config["assembly_nucmer_max_gap"])])
            if config.get("assembly_nucmer_min_match"):
                ono_extra.extend(["--minmatch", str(config["assembly_nucmer_min_match"])])
            if config.get("assembly_nucmer_min_cluster"):
                ono_extra.extend(["--mincluster", str(config["assembly_nucmer_min_cluster"])])
            if config.get("scaffold_min_pct_contig_aligned"):
                ono_extra.extend(["--min_pct_contig_aligned", str(config["scaffold_min_pct_contig_aligned"])])
            ono_extra = " ".join(ono_extra)
            shell("{config[bin_dir]}/assembly.py order_and_orient {input[0]} {params.refGenome} {params.scaffolded_fasta} {ono_extra} --outAlternateContigs {params.alternate_fasta}")
            shell("{config[bin_dir]}/read_utils.py index_fasta_all {params.scaffolded_fasta}")


rule fill_scaffold_gaps:
    ''' Fill gaps in assembly, using clean reads.
    '''
    input:  config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-scaffolded.fasta',
            config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-gapfilled.fasta'
    resources: 
            mem=45,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('long', '-q long'),
            logid="{sample}",
            numThreads=str(config.get("number_of_threads", 1))
    run:   
          shell("{config[bin_dir]}/assembly.py gapfill_sealer {input[0]} {input[1]} {output[0]} -k90  -b10 -P20 --sealer_opts='-j4'")
          shell("{config[bin_dir]}/read_utils.py index_fasta_all {output[0]}")



rule impute_from_reference:
    ''' This step cleans up the Trinity assembly with a known reference genome.
        order_and_orient (MUMmer): take the de novo assembly,
            align them to the known reference genome, switch it to the same
            strand as the reference, and produce chromosome-level assemblies
            (with runs of N's in between the de novo contigs).
        filter_short_seqs: Fail on assemblies that come out to
            < 15kb or < 95% unambiguous.
        impute_from_reference: trim off anything at the end that exceeds
            the length of the known reference assembly.  We also replace all
            Ns and everything within 55bp of the chromosome ends with the
            reference sequence.  This is clearly incorrect consensus sequence,
            but it allows downstream steps to map reads in parts of the genome
            that would otherwise be Ns, and we will correct all of the inferred
            positions with two steps of read-based refinement (below), and
            revert positions back to Ns where read support is lacking.  The
            de novo step is still important because it allows for significant
            structural / indel changes (or significant substitution distances)
            which will be captured in this output.
    '''
    input:  
        config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-gapfilled.fasta',
        expand( '{refDir}/'+'{ref_name}.fasta', refDir=config["ref_genome_dir"], ref_name="reference" )
    output: config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.fasta'
    resources: mem=12
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            refGenome=os.path.join(config["ref_genome_dir"],"reference"+".fasta"),
            # length should be defined as a fraction/percentage cutoff, relative to 
            # reference length for a given sequence. float is in the config.yaml file
            length = str(config["assembly_min_length_fraction_of_reference"]),
            min_unambig = str(config["assembly_min_unambig"]),
            renamed_prefix="",
            replace_length=str(config.get("assembly_replace_length", 55)),
            logid="{sample}",
    run:
            ono_extra = []
            if config.get("assembly_nucmer_max_gap"):
                ono_extra.extend(["--maxgap", str(config["assembly_nucmer_max_gap"])])
            if config.get("assembly_nucmer_min_match"):
                ono_extra.extend(["--minmatch", str(config["assembly_nucmer_min_match"])])
            if config.get("assembly_nucmer_min_cluster"):
                ono_extra.extend(["--mincluster", str(config["assembly_nucmer_min_cluster"])])
            if config.get("scaffold_min_pct_contig_aligned"):
                ono_extra.extend(["--min_pct_contig_aligned", str(config["scaffold_min_pct_contig_aligned"])])
            ono_extra = " ".join(ono_extra)
            shell("{config[bin_dir]}/assembly.py impute_from_reference {input[0]} {params.refGenome} {output} --newName {params.renamed_prefix}{wildcards.sample} --replaceLength {params.replace_length} --minLengthFraction {params.length} --minUnambig {params.min_unambig} --index")


rule orient_and_impute_spades:
    ''' This step cleans up the Trinity assembly with a known reference genome.
        order_and_orient (MUMmer): take the de novo assembly,
            align them to the known reference genome, switch it to the same
            strand as the reference, and produce chromosome-level assemblies
            (with runs of N's in between the de novo contigs).
        filter_short_seqs: Fail on assemblies that come out to
            < 15kb or < 95% unambiguous.
        impute_from_reference: trim off anything at the end that exceeds
            the length of the known reference assembly.  We also replace all
            Ns and everything within 55bp of the chromosome ends with the
            reference sequence.  This is clearly incorrect consensus sequence,
            but it allows downstream steps to map reads in parts of the genome
            that would otherwise be Ns, and we will correct all of the inferred
            positions with two steps of read-based refinement (below), and
            revert positions back to Ns where read support is lacking.  The
            de novo step is still important because it allows for significant
            structural / indel changes (or significant substitution distances)
            which will be captured in this output.
    '''
    input:  
        config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly1-spades.fasta',
        expand( '{refDir}/'+'{ref_name}.fasta', refDir=config["ref_genome_dir"], ref_name="reference" )
    output: config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.spades.fasta'
    resources: mem=12
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            refGenome=os.path.join(config["ref_genome_dir"],"reference"+".fasta"),
            # length should be defined as a fraction/percentage cutoff, relative to 
            # reference length for a given sequence. float is in the config.yaml file
            length = str(config["assembly_min_length_fraction_of_reference"]),
            min_unambig = str(config["assembly_min_unambig"]),
            renamed_prefix="",
            replace_length=str(config.get("assembly_replace_length", 55)),
            logid="{sample}",
            scaffolded_fasta=config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-scaffolded.spades.fasta',
            alternate_fasta=config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.assembly2-alternate_sequences.spades.fasta'
    run:
            ono_extra = []
            if config.get("assembly_nucmer_max_gap"):
                ono_extra.extend(["--maxgap", str(config["assembly_nucmer_max_gap"])])
            if config.get("assembly_nucmer_min_match"):
                ono_extra.extend(["--minmatch", str(config["assembly_nucmer_min_match"])])
            if config.get("assembly_nucmer_min_cluster"):
                ono_extra.extend(["--mincluster", str(config["assembly_nucmer_min_cluster"])])
            if config.get("scaffold_min_pct_contig_aligned"):
                ono_extra.extend(["--min_pct_contig_aligned", str(config["scaffold_min_pct_contig_aligned"])])
            ono_extra = " ".join(ono_extra)
            shell("{config[bin_dir]}/assembly.py order_and_orient {input[0]} {params.refGenome} {params.scaffolded_fasta} {ono_extra} --outAlternateContigs {params.alternate_fasta}")
            shell("{config[bin_dir]}/assembly.py impute_from_reference {params.scaffolded_fasta} {params.refGenome} {output} --newName {params.renamed_prefix}{wildcards.sample} --replaceLength {params.replace_length} --minLengthFraction {params.length} --minUnambig {params.min_unambig} --index")



rule refine_assembly_1:
    ''' This a first pass refinement step where we take the scaffolded assembly,
        align all reads back to it, and modify the assembly to the majority
        allele at each position based on read pileups.
        This step now considers both SNPs as well as indels called by GATK
        and will correct the consensus based on GATK calls.
        Reads are aligned with Novoalign with permissive mapping thresholds,
        then PCR duplicates are removed with Picard (in order to debias the
        allele counts in the pileups), and realigned with GATK's
        IndelRealigner (in order to call indels).
        Output FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3-modify.fasta',
            config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.vcf.gz',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly3.realigned.bam'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('long', '-q long'),
            logid="{sample}",
            novoalign_options = config.get("refine_assembly_1_novoalign_params", "-r Random -l 30 -g 40 -x 20 -t 502"),
            min_coverage = "2",
            numThreads=str(config.get("number_of_threads", 1))
    shell:  "{config[bin_dir]}/assembly.py refine_assembly {input} {output[0]} --outVcf {output[1]} --outBam {output[2]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --threads {params.numThreads}"

rule refine_assembly_2:
    ''' This a second pass refinement step very similar to the first.
        The only differences are that Novoalign mapping parameters are
        more conservative and the input consensus sequence has already
        been refined once. We also require higher minimum read coverage
        (3 instead of 2) in order to call a non-ambiguous base.
        The output of this step is the final assembly for this sample.
        Final FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
            config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: config["data_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.vcf.gz',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.realigned.bam'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('long', '-q long'),
            logid="{sample}",
            novoalign_options = config.get("refine_assembly_2_novoalign_params", "-r Random -l 40 -g 40 -x 20 -t 100"),
            min_coverage = "3",
            numThreads=str(config.get("number_of_threads", 1))
    shell:  "{config[bin_dir]}/assembly.py refine_assembly {input} {output[0]} --outVcf {output[1]} --outBam {output[2]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --threads {params.numThreads}"

rule map_reads_to_self:
    ''' After the final assembly is produced, we also produce BAM files with all reads
        mapped back to its own consensus.  Outputs several BAM files, sorted and indexed:
            {sample}.bam        - all raw reads aligned to self
            {sample}.mapped.bam - only mapped reads, duplicates removed by Picard,
                                  realigned with GATK IndelRealigner
    '''
    input:  config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam',
            config["data_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
    output: config["data_dir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.bam',
            config["data_dir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.mapped.bam'
    resources: 
            mem=4,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('long', '-q long'),
            logid="{sample}",
            aligner_options = config.get('map_reads_to_self_novoalign_params', "-r Random -l 40 -g 40 -x 20 -t 100 -k") if config.get('map_reads_to_self_aligner', "novoalign")=="novoalign" else "",
            aligner = config.get('map_reads_to_self_aligner', "novoalign"),
            numThreads=str(config.get("number_of_threads", 1))
    run:
            makedirs([os.path.join(config["data_dir"], config["subdirs"]["align_self"]),
                os.path.join(config["reports_dir"], "assembly")])
            shell("{config[bin_dir]}/read_utils.py align_and_fix {input} --outBamAll {output[0]} --outBamFiltered {output[1]} --aligner novoalign --aligner_options '{params.aligner_options}' --threads {params.numThreads}")

#########################################################################

rule compute_trimmed_rmduped_cleaned_reads:
    ''' Compute a trimmed and rmdupped version of cleaned reads.
    '''
    input:  config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.trim.rmdup.bam'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            n_reads=str(2000000),
            logid="{sample}",
            clipDb=config["trim_clip_db"],
            subsamp_bam=config["tmp_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.subsamp.bam',
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["data_dir"],config["tmp_dir"]],
                subdir=config["subdirs"]["per_sample"]))
            shell("{config[bin_dir]}/assembly.py trim_rmdup_subsamp {input} {params.clipDb} {output} --n_reads={params.n_reads}")

            
            

rule compute_kmc_kmer_db_for_cleaned:
    ''' Compute a kmc kmer db
    '''
    input:  config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: 
        config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.k{kmerSize}.kmc',
        config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.k{kmerSize}.kmc.hist.txt',
        config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.k{kmerSize}.kmc.dump.txt'

    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="{sample}"
    run:
            shell("{config[bin_dir]}/scafref.py kmc_build_db {input} {output[0]} {wildcards.kmerSize} --kmerOpts='-ci3' --histogram {output[1]} --dump {output[2]}")

            
rule compute_kmc_kmer_db_for_cleaned_trim_rmdup:
    ''' Compute a kmc kmer db
    '''
    input:  config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.trim.rmdup.bam'
    output: 
        config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.trim.rmdup.k{kmerSize}.kmc',
        config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.trim.rmdup.k{kmerSize}.kmc.hist.txt',
        config["tmp_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.trim.rmdup.k{kmerSize}.kmc.dump.txt'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="{sample}"
    run:
            shell("{config[bin_dir]}/scafref.py kmc_build_db {input} {output[0]} {wildcards.kmerSize} --kmerOpts='-ci3' --histogram {output[1]} --dump {output[2]}")


            
rule compute_kmc_kmer_db_generic:
    ''' Compute a kmc kmer db
    '''
    input:  "{X}.bam"
    output: 
        "{X}.bam.k{kmerSize}.kmc", "{X}.bam.k{kmerSize}.kmc.hist.txt", "{X}.bam.k{kmerSize}.dump.txt"
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short')
    run:
            shell("{config[bin_dir]}/scafref.py kmc_build_db {input} {output[0]} {wildcards.kmerSize} --kmerOpts='-ci1' --histogram {output[1]} --dump {output[2]}")




rule build_scafref:
    ''' Compute a kmc kmer db
    '''
    input:  'scafref/scafref.fasta'
    output: 'scafref/scafref.fasta.indexing.done'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short')
    run:
            shell("{config[bin_dir]}/scafref.py build_scafref_db scafref ref_genome/reference.fasta")
            

            
rule refine_assembly_2a_ambiguate_to_coverage:
    ''' Increase coverage by ambiguating the reference
    '''
    input:  config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined.fasta',
            #config["data_dir"]+'/'+config["subdirs"]["source"]+'/{sample}.bam'
            config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam',
    output: config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined-ambiguated.fasta',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.laxAlignBef.bam',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.strictAlignBef.bam',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.strictAlignAft.bam',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4.laxAlignAft.bam'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('long', '-q long'),
            logid="{sample}",
            novoalign_options_lax = "-r Random -l 40 -g 40 -x 20 -t 300",
            novoalign_options_strict = "-r Random -l 40 -g 40 -x 20 -t 100",
            min_coverage = "3",
            numThreads=str(config.get("number_of_threads", 1))
    shell:  "{config[bin_dir]}/assembly.py ambiguate_to_coverage --inFasta {input[0]} --inBam {input[1]} --outFasta {output[0]} --outBamLaxBef {output[1]} --maxAlignStrictScore 100 --maxAlignLaxScore 300 --minDepth {params.min_coverage}  --threads {params.numThreads} --novo_params_lax '{params.novoalign_options_lax}'  --novo_params_strict '{params.novoalign_options_strict}' --outBamStrictBef {output[2]} --outBamStrictAft {output[3]} --outBamLaxAft {output[4]}"


    
rule refine_assembly_2b:
    ''' This a second pass refinement step very similar to the first.
        The only differences are that Novoalign mapping parameters are
        more conservative and the input consensus sequence has already
        been refined once. We also require higher minimum read coverage
        (3 instead of 2) in order to call a non-ambiguous base.
        The output of this step is the final assembly for this sample.
        Final FASTA file is indexed for Picard, Samtools, and Novoalign.
    '''
    input:  config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.assembly4-refined-ambiguated.fasta',
            config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam'
    output: config["data_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.2b.fasta',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.2b.assembly4.vcf.gz',
            config["tmp_dir"] +'/'+config["subdirs"]["assembly"]+'/{sample}.2b.assembly4.realigned.bam'
    resources: 
            mem=7,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('long', '-q long'),
            logid="{sample}",
            novoalign_options = config.get("refine_assembly_2_novoalign_params", "-r Random -l 40 -g 40 -x 20 -t 100"),
            min_coverage = "3",
            numThreads=str(config.get("number_of_threads", 1))
    shell:  "{config[bin_dir]}/assembly.py refine_assembly {input} {output[0]} --outVcf {output[1]} --outBam {output[2]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --threads {params.numThreads}"

rule map_reads_to_self_2b:
    ''' After the final assembly is produced, we also produce BAM files with all reads
        mapped back to its own consensus.  Outputs several BAM files, sorted and indexed:
            {sample}.bam        - all raw reads aligned to self
            {sample}.mapped.bam - only mapped reads, duplicates removed by Picard,
                                  realigned with GATK IndelRealigner
    '''
    input:  config["data_dir"]+'/'+config["subdirs"]["per_sample"]+'/{sample}.cleaned.bam',
            config["data_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.2b.fasta'
    output: config["data_dir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.2b.bam',
            config["data_dir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.2b.mapped.bam'
    resources: 
            mem=4,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('long', '-q long'),
            logid="{sample}",
            aligner_options = config.get('map_reads_to_self_novoalign_params', "-r Random -l 40 -g 40 -x 20 -t 100 -k") if config.get('map_reads_to_self_aligner', "novoalign")=="novoalign" else "",
            aligner = config.get('map_reads_to_self_aligner', "novoalign"),
            numThreads=str(config.get("number_of_threads", 1))
    run:
            makedirs([os.path.join(config["data_dir"], config["subdirs"]["align_self"]),
                os.path.join(config["reports_dir"], "assembly")])
            shell("{config[bin_dir]}/read_utils.py align_and_fix {input} --outBamAll {output[0]} --outBamFiltered {output[1]} --aligner novoalign --aligner_options '{params.aligner_options}' --threads {params.numThreads}")

