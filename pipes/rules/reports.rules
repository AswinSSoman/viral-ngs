"""
    These rules generate reports and metrics on reads and assemblies.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, gzip, shutil


rule all_reports:
    input:
        config["reports_dir"]+'/summary.fastqc.txt',
        config["reports_dir"]+'/summary.spike_count.txt'
    params: LSF="-N"


#-----------FASTQC---------------------

rule fastqc_report:
    input:  config["data_dir"]+'/'+config["subdirs"]["align_self"]+'/{sample}.bam'
    output: config["reports_dir"]+'/fastqc/{sample}_fastqc'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="{sample}"
    run:
            makedirs(config["reports_dir"])
            shutil.rmtree(output[0], ignore_errors=True)
            makedirs(os.path.join(config["reports_dir"], 'fastqc'))
            shell("/idi/sabeti-scratch/kandersen/bin/fastqc/fastqc -f bam {input} -o {config[reports_dir]}/fastqc")
            os.unlink(output[0]+'.zip')

rule consolidate_fastqc:
    input:
            expand("{{dir}}/fastqc/{sample}_fastqc",
                sample=read_samples_file(config["samples_assembly"]))
    output: '{dir}/summary.fastqc.txt'
    params: logid="all"
    shell:  "{config[bin_dir]}/reports.py consolidate_fastqc {input} {output}"


#-----------SPIKE-INS------------------

rule spikein_report:
    input:  config["data_dir"]+'/'+config["subdirs"]["depletion"]+'/{sample}.cleaned.bam'
    output: config["reports_dir"]+'/spike_count/{sample}.spike_count.txt'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="{sample}",
            spikeins_db=config["spikeins_db"],
            numThreads=str(config.get("number_of_threads", 1))
    run:
            makedirs(os.path.join(config["reports_dir"], 'spike_count'))
            makedirs(os.path.join(config["tmp_dir"], config["subdirs"]["depletion"]))
            shell("{config[bin_dir]}/read_utils.py align_and_count_hits {input} {params.spikeins_db} {output} --threads={params.numThreads}")

rule consolidate_spike_count:
    input:  expand("{{dir}}/spike_count/{sample}.spike_count.txt", \
                sample=read_samples_file(config["samples_per_run"]))
    output: '{dir}/summary.spike_count.txt'
    params: logid="all"
    shell:  "{config[bin_dir]}/reports.py consolidate_spike_count {wildcards.dir}/spike_count {output}"

