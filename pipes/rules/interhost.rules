"""
    This is a basic framework for alignment and SNP calling in viral genomes,
    currently tailored for EBOV.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time


def merge_vcfs(inFiles, refFasta, outFile):
    inFilesString = ' '.join(['--variant '+i for i in inFiles])
    shell("java -Xmx2g -jar /humgen/gsa-hpprojects/GATK/bin/GenomeAnalysisTK-3.3-0-g37228af/GenomeAnalysisTK.jar" \
        + " -T CombineVariants -R {refFasta} {inFilesString} -o {outFile}" \
        + " --genotypemergeoption UNIQUIFY")

def update_timestamps(files):
    ''' this dumb function exists because sometimes the different nodes on the
        cluster have out-of-sync system clocks and snakemake fails if the mtime of
        any input file is more recent than the mtimes of the output files
    '''
    for f in files:
        if os.path.isfile(f) and os.path.getmtime(f) > time.time():
            print("input file %s is more recent than present, resetting its modification time to present" % f)
            os.utime(f)

rule all_ref_guided:
    input:
            os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.fasta'),
            os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.vcf.gz')

rule ref_guided_consensus:
    input:  config["dataDir"]+'/'+config["subdirs"]["source"]+'/{sample}.bam'
    output: config["dataDir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.realigned.bam',
            config["dataDir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.vcf.gz',
            config["dataDir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.fasta'
    resources: mem=4
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="{sample}",
            refGenome=config["ref_genome"],
            novoalign_options="-r Random -l 30 -g 40 -x 20 -t 502",
            min_coverage="3"
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["dataDir"]],
                subdir=[config["subdirs"]["align_ref"], config["subdirs"]["interhost"]]))
            shell("{config[binDir]}/assembly.py refine_assembly {params.refGenome} {input} {output[2]} --outBam {output[0]} --outVcf {output[1]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --keep_all_reads --chr_names {wildcards.sample}")

rule ref_guided_diversity:
    input:  
            expand("{dataDir}/{subdir}/{sample}.{ext}",
                dataDir=config["dataDir"],
                subdir=config["subdirs"]["align_ref"],
                ext = ['fasta', 'vcf.gz'],
                sample=read_samples_file(config["samples_per_run"]))
    output: os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.fasta'),
            os.path.join(config["dataDir"], config["subdirs"]["interhost"], 'ref_guided.vcf.gz')
    resources: mem=8
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="all",
            refGenome=config["ref_genome"],
            inFastas = expand("{dataDir}/{subdir}/{sample}.fasta",
                dataDir=config["dataDir"], subdir=config["subdirs"]["align_ref"],
                sample=read_samples_file(config["samples_per_run"])),
            inVcfs = expand("{dataDir}/{subdir}/{sample}.vcf.gz",
                dataDir=config["dataDir"], subdir=config["subdirs"]["align_ref"],
                sample=read_samples_file(config["samples_per_run"]))
    run:
            update_timestamps(input)
            shell("cat {params.inFastas} > {output[0]}")
            merge_vcfs(params.inVcfs, params.refGenome, output[1])


rule annot_transfer:
    input:      config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
    output:     config["dataDir"]+'/'+config["subdirs"]["annot"]   +'/{sample}.tbl'
    resources:  mem=4
    params:     LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
                logid="{sample}",
                refGenome=config["ref_genome"],
                refAnnot=config["ref_annot"]
    shell:      "{config[binDir]}/ncbi.py tbl_transfer {params.refGenome} {params.refAnnot} {input} {output} --oob_clip"

rule prepare_genbank:
    input:
                config["reportsDir"]+"/summary.assembly.txt",
                expand("{dir}/{subdir}/{sample}.tbl",
                    dir=[config["dataDir"]], subdir=[config["subdirs"]["annot"]],
                    sample=read_samples_file(config["samples_assembly"]))
    output:
                config["dataDir"]+'/'+config["subdirs"]["annot"]+'/errorsummary.val'
    params:
                LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
                fasta_files=expand("{dir}/{subdir}/{sample}.fasta",
                    dir=[config["dataDir"]], subdir=[config["subdirs"]["assembly"]],
                    sample=read_samples_file(config["samples_assembly"])),
                genbank_template=config.get('genbank',{}).get('author_template', ''),
                genbank_source_table=config.get('genbank',{}).get('source_modifier_table', ''),
                biosample_map=config.get('genbank',{}).get('biosample_map', ''),
                seq_tech=config.get('genbank',{}).get('sequencing_technology', 'unknown'),
                comment=config.get('genbank',{}).get('comment', ''),
                logid="all"
    shell:
                ' '.join(["{config[binDir]}/ncbi.py prep_genbank_files",
                    "{params.genbank_template} {params.fasta_files}",
                    "{config[dataDir]}/{config[subdirs][annot]}",
                    "--master_source_table {params.genbank_source_table}",
                    "--sequencing_tech '{params.seq_tech}'",
                    "--biosample_map {params.biosample_map}",
                    "--coverage_table {config[reportsDir]}/summary.assembly.txt",
                    "--comment '{params.comment}'"])

rule all_annot:
    input:
                config["dataDir"]+'/'+config["subdirs"]["annot"]+'/errorsummary.val'


rule multi_align_mafft:
    input:
        expand("{dataDir}/{subdir}/{sample}.fasta",
                dataDir=config["dataDir"],
                subdir=config["subdirs"]["assembly"],
                sample=read_samples_file(config["samples_assembly"]))
    output:
        expand("{dataDir}/{subdir}/aligned_{chrom}.fasta",
                dataDir=config["dataDir"],
                subdir=config["subdirs"]["multialign_ref"],
                chrom=range(config["number_of_chromosomes"]))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="all",
            refGenome=config["ref_genome"],
            snpEff_ref=config["snpEff_genome"],
            samples=read_samples_file(config["samples_assembly"]),
            ep=str(config["mafft_ep"]),
            maxiters=str(config["mafft_maxiters"])
    run:
        shell("{config[binDir]}/interhost.py multichr_mafft {params.refGenome} "
                + " ".join(["{config[dataDir]}/{config[subdirs][assembly]}/" + s + ".fasta" for s in params.samples])
                + " {config[dataDir]}/{config[subdirs][multialign_ref]}"
                + " --ep {params.ep} --maxiters {params.maxiters} --preservecase"
                + " --localpair --outFilePrefix aligned_")

'''
rule multi_align_mafft:
    input:  config["dataDir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
        expand("{dataDir}/{subdir}/{sample}.fasta",
            dataDir=config["dataDir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
    output: config["dataDir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.pruned.phy'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="all",
            tmpf_mafft=config["tmpDir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.mafft.fasta',
            log_trimal=config["tmpDir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.log.trimal.html'
    # TODO: replace with python wrapper
    run:
            makedirs(os.path.join(config["dataDir"], config["subdirs"]["interhost"]),
                os.path.join(config["tmpDir"], config["subdirs"]["interhost"]))
            shell("/idi/sabeti-scratch/kandersen/bin/mafft/core/mafft --localpair --maxiterate 1000 --reorder --ep 0.123 --preservecase --thread 4 {input} > {params.tmpf_mafft}")
            shell("/idi/sabeti-scratch/kandersen/bin/trimal/trimal -phylip -automated1 -in {params.tmpf_mafft} -out {output} -htmlout {params.log_trimal} -colnumbering")
            update_timestamps(input)


# Make sure all file-names are unique when cut down to 10 characters - e.g. if analysing Lassa 'LASV-' identifier needs to be removed from the input sequence file.


#-------- SEQUENCE ALIGNMENT --------#

#-------- TREE BUILDING USING MAXIMUM LIKELIHOOD - RAXML --------#
# CREATE TREE
for sequences in
do
for directory in
do
for substitution_model in GTRGAMMA
do
for bootstraps in 500
do
bsub -sp 100 -R "rusage[mem=2]" -n 2 -R "span[hosts=1]" -W 4:00 -q hour -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.tr1 "/idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-PTHREADS-SSE3 -f d -T 2 -p 123421 -m $substitution_model -N 20 -n $sequences.tree1 -w $directory/_trees/ -s $directory/_msa/$sequences.pruned.phy"
bsub -sp 90 -n 4 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.tr2 "/idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-PTHREADS-SSE3 -f d -T 4 -p 12438 -m $substitution_model -b 12438 -N $bootstraps -k -n $sequences.tree2 -w $directory/_trees/ -s $directory/_msa/$sequences.pruned.phy && /idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-SSE3 -T 1 -m $substitution_model -n $sequences.tree3 -f b -t $directory/_trees/RAxML_bestTree.$sequences.tree1 -z $directory/_trees/RAxML_bootstrap.$sequences.tree2 -w $directory/_trees/ && mv $directory/_trees/RAxML_bipartitions.$sequences.tree3 $directory/_trees/$sequences.raxml.tree"
done
done
done
done

#-------- CREATE TREES USING PHYML --------#
# CREATE TREE
for sequences in
do
for directory in
do
for substitution_model in GTR # HKY85, JC69, K80, F81, F84, TN93
do
for bootstraps in 500
do
bsub -n 1 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.pm "/idi/sabeti-scratch/kandersen/bin/phyml/PhyML-3.1_linux64 -i $directory/_msa/$sequences.pruned.phy -d nt -b $bootstraps -m $substitution_model --pinv 0 --nclasses 4 -s BEST --rand_start --n_rand_starts 10 --r_seed 1553 -f m --no_memory_check && mv $directory/_msa/$sequences.pruned.phy_phyml* $directory/_trees/ && /idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-SSE3 -f b -t $directory/_trees/$sequences.pruned.phy_phyml_tree.txt -z $directory/_trees/$sequences.pruned.phy_phyml_boot_trees.txt -m GTRGAMMA -s $directory/_msa/$sequences.pruned.phy -n $sequences.phyml.tree -w $directory/_trees/ && mv $directory/_trees/RAxML_bipartitions.$sequences.phyml.tree $directory/_trees/$sequences.phyml.tree"
done
done
done
done

#-------- CREATE TREES USING MR BAYES --------#
# OUTPUT NEXUS FILE
for sequences in
do
for directory in
do
bsub -R "rusage[mem=2]" -n 1 -R "span[hosts=1]" -W 4:00 -q hour -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.pr "/idi/sabeti-scratch/kandersen/bin/trimal/trimal -automated1 -in $directory/_msa/$sequences.pruned.phy -nexus -out $directory/_msa/$sequences.pruned.nex"
done
done

# RUN MR BAYES
for sequences in
do
for directory in
do
bsub -R "rusage[mem=2]" -n 1 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.mb "cp $directory/_msa/$sequences.pruned.nex $directory/_trees/mr-bayes/$sequences.nex && /idi/sabeti-scratch/kandersen/bin/mrbayes/run_mrbayes.sh $directory/_trees/mr-bayes/$sequences.nex"
done
done



#----do snp calling w/rachel's script & snpEff
'''






