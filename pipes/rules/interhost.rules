"""
    This is a basic framework for alignment and SNP calling in viral genomes,
    currently tailored for EBOV.
"""

__author__ = 'Kristian Andersen <andersen@broadinstitute.org>, Daniel Park <dpark@broadinstitute.org>'

from snakemake.utils import makedirs
import os, os.path, time


def merge_vcfs(inFiles, refFasta, outFile):
    inFilesString = ' '.join(['--variant '+i for i in inFiles])
    shell("java -Xmx2g -jar /humgen/gsa-hpprojects/GATK/bin/GenomeAnalysisTK-3.3-0-g37228af/GenomeAnalysisTK.jar" \
        + " -T CombineVariants -R {refFasta} {inFilesString} -o {outFile}" \
        + " --genotypemergeoption UNIQUIFY")

def update_timestamps(files):
    ''' this dumb function exists because sometimes the different nodes on the
        cluster have out-of-sync system clocks and snakemake fails if the mtime of
        any input file is more recent than the mtimes of the output files
    '''
    for f in files:
        if os.path.isfile(f) and os.path.getmtime(f) > time.time():
            print("input file %s is more recent than present, resetting its modification time to present" % f)
            os.utime(f)

rule all_ref_guided:
    input:
            os.path.join(config["data_dir"], config["subdirs"]["interhost"], 'ref_guided.fasta'),
            os.path.join(config["data_dir"], config["subdirs"]["interhost"], 'ref_guided.vcf.gz')

rule ref_guided_consensus:
    input:  
            config["data_dir"]+'/'+config["subdirs"]["source"]+'/{sample}.bam',
            expand( '{refDir}/'+'{ref_name}.fasta', refDir=config["ref_genome_dir"], ref_name="reference" )
    output: config["data_dir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.realigned.bam',
            config["data_dir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.vcf.gz',
            config["data_dir"]+'/'+config["subdirs"]["align_ref"]+'/{sample}.fasta'
    resources: 
            mem=4,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="{sample}",
            refGenome=os.path.join(config["ref_genome_dir"],"reference"+".fasta"),
            novoalign_options="-r Random -l 30 -g 40 -x 20 -t 502",
            min_coverage="3",
            numThreads=str(config.get("number_of_threads", 1))
    run:
            makedirs(expand("{dir}/{subdir}",
                dir=[config["data_dir"]],
                subdir=[config["subdirs"]["align_ref"], config["subdirs"]["interhost"]]))
            shell("{config[bin_dir]}/assembly.py refine_assembly {params.refGenome} {input} {output[2]} --outBam {output[0]} --outVcf {output[1]} --min_coverage {params.min_coverage} --novo_params '{params.novoalign_options}' --keep_all_reads --chr_names {wildcards.sample} --threads {params.numThreads}")

rule ref_guided_diversity:
    input:  
            expand("{data_dir}/{subdir}/{sample}.{ext}",
                data_dir=config["data_dir"],
                subdir=config["subdirs"]["align_ref"],
                ext = ['fasta', 'vcf.gz'],
                sample=read_samples_file(config["samples_per_run"])),
            expand( '{refDir}/'+'/{ref_name}.fasta', refDir=config["ref_genome_dir"], ref_name="reference" )
    output: 
            os.path.join(config["data_dir"], config["subdirs"]["interhost"], 'ref_guided.fasta'),
            os.path.join(config["data_dir"], config["subdirs"]["interhost"], 'ref_guided.vcf.gz')
    resources: mem=8
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="all",
            refGenome=os.path.join(config["ref_genome_dir"],"reference"+".fasta"),
            inFastas = expand("{data_dir}/{subdir}/{sample}.fasta",
                data_dir=config["data_dir"], subdir=config["subdirs"]["align_ref"],
                sample=read_samples_file(config["samples_per_run"])),
            inVcfs = expand("{data_dir}/{subdir}/{sample}.vcf.gz",
                data_dir=config["data_dir"], subdir=config["subdirs"]["align_ref"],
                sample=read_samples_file(config["samples_per_run"]))
    run:
            update_timestamps(input)
            shell("cat {params.inFastas} > {output[0]}")
            merge_vcfs(params.inVcfs, params.refGenome, output[1])

rule multi_align_mafft:
    input:
        expand("{data_dir}/{subdir}/{sample}.fasta",
                data_dir=config["data_dir"],
                subdir=config["subdirs"]["assembly"],
                sample=read_samples_file(config["samples_assembly"])),
        expand( '{refDir}/'+'{ref_name}.fasta', refDir=config["ref_genome_dir"], ref_name="reference" )
    output:
        config["data_dir"]+'/'+config["subdirs"]["multialign_ref"] + "/sampleNameList.txt",
        expand("{data_dir}/{subdir}/aligned_{chrom}.fasta",
                data_dir=config["data_dir"],
                subdir=config["subdirs"]["multialign_ref"],
                chrom=range(1, len(config["accessions_for_ref_genome_build"])+1))        
    resources: 
            mem=8,
            cores=int(config.get("number_of_threads", 1))
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            UGER=config.get('UGER_queues', {}).get('short', '-q short'),
            logid="all",
            refGenome=os.path.join(config["ref_genome_dir"],"reference"+".fasta"),
            snpEff_ref=config["accessions_for_ref_genome_build"],
            samples=read_samples_file(config["samples_assembly"]),
            ep=str(config["mafft_ep"]),
            maxiters=str(config["mafft_maxiters"]),
            numThreads=str(config.get("number_of_threads", 1))
    run:
        shell("{config[bin_dir]}/interhost.py multichr_mafft {params.refGenome} "
                + " ".join(["{config[data_dir]}/{config[subdirs][assembly]}/" + s + ".fasta" for s in params.samples])
                + " {config[data_dir]}/{config[subdirs][multialign_ref]}"
                + " --ep {params.ep} --maxiters {params.maxiters} --preservecase"
                + " --localpair --outFilePrefix aligned --sampleNameListFile {output[0]} --threads {params.numThreads}")

'''
rule multi_align_mafft:
    input:  config["data_dir"]+'/'+config["subdirs"]["assembly"]+'/{sample}.fasta'
        expand("{data_dir}/{subdir}/{sample}.fasta",
            data_dir=config["data_dir"], subdir=config["subdirs"]["assembly"],
            sample=read_samples_file(config["samples_assembly"])),
    output: config["data_dir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.pruned.phy'
    resources: mem=3
    params: LSF=config.get('LSF_queues', {}).get('short', '-W 4:00'),
            logid="all",
            tmpf_mafft=config["tmp_dir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.mafft.fasta',
            log_trimal=config["tmp_dir"]+'/'+config["subdirs"]["interhost"]+'/{sample}.log.trimal.html'
    # TODO: replace with python wrapper
    run:
            makedirs(os.path.join(config["data_dir"], config["subdirs"]["interhost"]),
                os.path.join(config["tmp_dir"], config["subdirs"]["interhost"]))
            shell("/idi/sabeti-scratch/kandersen/bin/mafft/core/mafft --localpair --maxiterate 1000 --reorder --ep 0.123 --preservecase --thread 4 {input} > {params.tmpf_mafft}")
            shell("/idi/sabeti-scratch/kandersen/bin/trimal/trimal -phylip -automated1 -in {params.tmpf_mafft} -out {output} -htmlout {params.log_trimal} -colnumbering")
            update_timestamps(input)


# Make sure all file-names are unique when cut down to 10 characters - e.g. if analysing Lassa 'LASV-' identifier needs to be removed from the input sequence file.


#-------- SEQUENCE ALIGNMENT --------#

#-------- TREE BUILDING USING MAXIMUM LIKELIHOOD - RAXML --------#
# CREATE TREE
for sequences in
do
for directory in
do
for substitution_model in GTRGAMMA
do
for bootstraps in 500
do
bsub -sp 100 -R "rusage[mem=2]" -n 2 -R "span[hosts=1]" -W 4:00 -q hour -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.tr1 "/idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-PTHREADS-SSE3 -f d -T 2 -p 123421 -m $substitution_model -N 20 -n $sequences.tree1 -w $directory/_trees/ -s $directory/_msa/$sequences.pruned.phy"
bsub -sp 90 -n 4 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.tr2 "/idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-PTHREADS-SSE3 -f d -T 4 -p 12438 -m $substitution_model -b 12438 -N $bootstraps -k -n $sequences.tree2 -w $directory/_trees/ -s $directory/_msa/$sequences.pruned.phy && /idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-SSE3 -T 1 -m $substitution_model -n $sequences.tree3 -f b -t $directory/_trees/RAxML_bestTree.$sequences.tree1 -z $directory/_trees/RAxML_bootstrap.$sequences.tree2 -w $directory/_trees/ && mv $directory/_trees/RAxML_bipartitions.$sequences.tree3 $directory/_trees/$sequences.raxml.tree"
done
done
done
done

#-------- CREATE TREES USING PHYML --------#
# CREATE TREE
for sequences in
do
for directory in
do
for substitution_model in GTR # HKY85, JC69, K80, F81, F84, TN93
do
for bootstraps in 500
do
bsub -n 1 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.pm "/idi/sabeti-scratch/kandersen/bin/phyml/PhyML-3.1_linux64 -i $directory/_msa/$sequences.pruned.phy -d nt -b $bootstraps -m $substitution_model --pinv 0 --nclasses 4 -s BEST --rand_start --n_rand_starts 10 --r_seed 1553 -f m --no_memory_check && mv $directory/_msa/$sequences.pruned.phy_phyml* $directory/_trees/ && /idi/sabeti-scratch/kandersen/bin/raxml/raxmlHPC-SSE3 -f b -t $directory/_trees/$sequences.pruned.phy_phyml_tree.txt -z $directory/_trees/$sequences.pruned.phy_phyml_boot_trees.txt -m GTRGAMMA -s $directory/_msa/$sequences.pruned.phy -n $sequences.phyml.tree -w $directory/_trees/ && mv $directory/_trees/RAxML_bipartitions.$sequences.phyml.tree $directory/_trees/$sequences.phyml.tree"
done
done
done
done

#-------- CREATE TREES USING MR BAYES --------#
# OUTPUT NEXUS FILE
for sequences in
do
for directory in
do
bsub -R "rusage[mem=2]" -n 1 -R "span[hosts=1]" -W 4:00 -q hour -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.pr "/idi/sabeti-scratch/kandersen/bin/trimal/trimal -automated1 -in $directory/_msa/$sequences.pruned.phy -nexus -out $directory/_msa/$sequences.pruned.nex"
done
done

# RUN MR BAYES
for sequences in
do
for directory in
do
bsub -R "rusage[mem=2]" -n 1 -R "span[hosts=1]" -q week -o $directory/_logs/$sequences.log.bsub.txt -P sabeti_trees -J $sequences.mb "cp $directory/_msa/$sequences.pruned.nex $directory/_trees/mr-bayes/$sequences.nex && /idi/sabeti-scratch/kandersen/bin/mrbayes/run_mrbayes.sh $directory/_trees/mr-bayes/$sequences.nex"
done
done



#----do snp calling w/rachel's script & snpEff
'''






